{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#6.1-基于最大间隔分隔数据\" data-toc-modified-id=\"6.1-基于最大间隔分隔数据-1\">6.1 基于最大间隔分隔数据</a></span></li><li><span><a href=\"#6.2-寻找最大间隔\" data-toc-modified-id=\"6.2-寻找最大间隔-2\">6.2 寻找最大间隔</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.2.1-分类器求解优化问题\" data-toc-modified-id=\"6.2.1-分类器求解优化问题-2.1\">6.2.1 分类器求解优化问题</a></span></li><li><span><a href=\"#6.2.2-SVM应用的一般框架\" data-toc-modified-id=\"6.2.2-SVM应用的一般框架-2.2\">6.2.2 SVM应用的一般框架</a></span></li></ul></li><li><span><a href=\"#6.3-SMO高效优化算法\" data-toc-modified-id=\"6.3-SMO高效优化算法-3\">6.3 SMO高效优化算法</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.3.1-Platt的SMO算法\" data-toc-modified-id=\"6.3.1-Platt的SMO算法-3.1\">6.3.1 Platt的SMO算法</a></span></li><li><span><a href=\"#6.3.2-应用简化版SMO算法处理小规模数据集\" data-toc-modified-id=\"6.3.2-应用简化版SMO算法处理小规模数据集-3.2\">6.3.2 应用简化版SMO算法处理小规模数据集</a></span></li></ul></li><li><span><a href=\"#6.4-利用完整Platt-SMO算法加速优化\" data-toc-modified-id=\"6.4-利用完整Platt-SMO算法加速优化-4\">6.4 利用完整Platt SMO算法加速优化</a></span></li><li><span><a href=\"#6.5-在复杂数据上应用核函数\" data-toc-modified-id=\"6.5-在复杂数据上应用核函数-5\">6.5 在复杂数据上应用核函数</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.5.1-利用核函数将数据映射到高维空间\" data-toc-modified-id=\"6.5.1-利用核函数将数据映射到高维空间-5.1\">6.5.1 利用核函数将数据映射到高维空间</a></span></li><li><span><a href=\"#6.5.2-径向基核函数\" data-toc-modified-id=\"6.5.2-径向基核函数-5.2\">6.5.2 径向基核函数</a></span></li></ul></li><li><span><a href=\"#6.6-示例：手写识别问题回顾\" data-toc-modified-id=\"6.6-示例：手写识别问题回顾-6\">6.6 示例：手写识别问题回顾</a></span></li><li><span><a href=\"#6.7-本章小结\" data-toc-modified-id=\"6.7-本章小结-7\">6.7 本章小结</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "这里介绍SVM一种最流行的实现，序列最小化优化(Sequential Minimal Optimization, SMO)算法，并介绍如何通过核函数的方式拓展SVM到更多的数据集。\n",
    "## 6.1 基于最大间隔分隔数据\n",
    "- 优点：泛化错误率低，计算开销不大，结果易解释\n",
    "- 缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二分类问题\n",
    "- 适用数据类型：数值型和标称性数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一些概念：**\n",
    "- 分隔超平面：将数据集划分开的超平面，若数据集的维度是N，则该超平面的维度是N-1\n",
    "- 间隔：数据点到分隔面的距离\n",
    "- 支持向量：离分隔面最近的那些数据点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 寻找最大间隔\n",
    "分隔超平面$W^T X+b$,要计算点A到分隔超平面的距离，必须给出分隔面法线或者垂线长度，该值为$\\frac{W^T X+b}\n",
    "{||W||}$\n",
    "### 6.2.1 分类器求解优化问题\n",
    "输入数据给分类器会输出一个类别标签，$f(u)$, 当$u<0$时，输出-1；反之，输出1。当数据点正确分类且距离分隔超平面很远时，$label*(W^TX+b)$会是一个很大的正数。\n",
    "\n",
    "SVM的目标是找到最小间隔的数据点，得到间隔的最大化：\n",
    "$$argmax_{w,b}\\{min_n(lable(W^T+b))\\frac{1}{||W||}\\}$$\n",
    "$$s.t.\\quad label(W^TX+b)\\quad\\geq \\quad1$$\n",
    "引入拉格朗日乘子法，将超平面写成数据点的形式：\n",
    "$$max_a[\\sum_{i=1}^{m}\\alpha-\\frac{1}{2}\\sum_{i,j=1}^{m}label^{(i)}\\cdot label^{(i)}\\cdot a_i\\cdot a_j <x^{(i)}, x^{(j)}>]$$\n",
    "$$a\\geq0,\\quad and \\sum_{i-1}{m}a_i\\cdot label^{(i)}=0$$\n",
    "\n",
    "这里有一个假设：数据必须100%线性可分，对于有扰动数据点的数据，引入松弛变量来允许数据点可以处于分隔面的错误一侧，这样我们的优化目标保持不变，更新约束规则：\n",
    "$$s.t.\\quad C \\geq \\alpha \\geq 0, \\quad and \\sum_{i-1}^{m} \\alpha _i \\cdot label^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 SVM应用的一般框架\n",
    "1. 收集数据：可以使用任意方法\n",
    "2. 准备数据：需要数值型数据\n",
    "3. 分析数据：有助于可视化分隔超平面\n",
    "4. 训练算法：SVM的大部分时间都源自于训练，该过程主要实现两个参数的调优\n",
    "5. 测试算法：十分简单的计算过程就可以实现\n",
    "6. 使用算法：几乎所有分类问题都可以使用SVM，值得一提的是，SVM本事是一个二分类器，对于多问题应用SVM需要对代码做一些修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 SMO高效优化算法\n",
    "训练算法，是对上面两个公式进行求解，一个是最小化目标函数，一个是约束条件。可以使用二次规划求解工具进行求解，一旦得到最优的$\\alpha$的值，我们就得到了分隔超平面并能够将数据分类。\n",
    "### 6.3.1 Platt的SMO算法\n",
    "SMO算法的工作原理是：每次循环选择两个alpha进行优化处理，一旦找到一对合适的alpha（$\\alpha _i, \\alpha_j$）那么就增大其中一个同时减小另一个。\n",
    "**条件:** 这两个alpha必须要在间隔边界之外，另该两个alpha为经过区间化处理或在边界上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 应用简化版SMO算法处理小规模数据集\n",
    "SMO算法的外循环会确定要优化最佳alpha对，而简化版会跳过这一部分，首先在数据集上遍历一个alpha，然后在剩下的alpha集合中随机选择另一个alpha，从而构建alpha对，这里有一点很重要，我们要同时改变两个alpha，可以这么做是因为我们有一个约束：\n",
    "$$\\sum \\alpha_i \\cdot label^{(i)} = 0$$\n",
    "接下来，构建一个辅助函数，用于在某个区间范围内随机选择一个整数，同时构建另一个函数，用于数值太大时对其进行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    '''读取数据，按行从txt中读取，前两列是数据点坐标，最后一列是分类label\n",
    "    传入：\n",
    "    fileName：文件路径\n",
    "    返回：\n",
    "    dataMat：数据点坐标数据矩阵，m×2\n",
    "    labelMat：数据类别标签，m×1\n",
    "    '''\n",
    "    dataMat, labelMat = [], []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "def selectJrand(i, m):\n",
    "    '''返回一个0到m以内，与i不同的整数\n",
    "    传入：\n",
    "       i： 第一个alpha值的下标，\n",
    "       m： 数据量的多少\n",
    "    返回：\n",
    "    j：一个0到m，与i不同的整数\n",
    "    '''\n",
    "    j = i\n",
    "    while (j==i):\n",
    "        j = int(random.uniform(0, m))\n",
    "    return j\n",
    "def clipAlpha(aj, H, L):\n",
    "    '''约束alpha_j的上界和下界\n",
    "    传入：\n",
    "    aj： alpha值\n",
    "    H：上界\n",
    "    L：下届\n",
    "    返回：约束后的alpha值\n",
    "    '''\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArr, labelArr = loadDataSet('testSet.txt')\n",
    "labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    '''简单的SMO SVM实现，学习带约束目标的alpha值和偏置\n",
    "    传入：\n",
    "    dataMatIn：数据矩阵\n",
    "    classLabels：类别标签\n",
    "    C：上界\n",
    "    toler：容错值\n",
    "    maxIter：最大迭代数\n",
    "    返回：\n",
    "    b：偏置\n",
    "    alpha：优化目标中的alpha值\n",
    "    '''\n",
    "    dataMatrix = mat(dataMatIn)\n",
    "    labelMat = mat(classLabels).transpose()    # 类标矩阵转置\n",
    "    m, n = shape(dataMatrix)\n",
    "    b = 0\n",
    "    alphas = mat(zeros((m,1)))   # 学习率\n",
    "    iter = 0\n",
    "    while (iter < maxIter):    # 外循环，最大迭代次数\n",
    "        alphaPairsChanged = 0    # flag，alpha对是否同时改变\n",
    "        for i in range(m):\n",
    "            fXi = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b    # 预测类别\n",
    "            Ei = fXi - float(labelMat[i])    # 偏差\n",
    "            #if checks if an example violates KKT conditions\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "                j = selectJrand(i,m)    # 随机选择另一个alpha j\n",
    "                fXj = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                alphaIold = alphas[i].copy()    # Python非引用复制\n",
    "                alphaJold = alphas[j].copy()\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H:     # 上下界收敛，继续iterate\n",
    "                    print \"L==H\"\n",
    "                    continue\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if eta >= 0: \n",
    "                    print \"eta>=0\"\n",
    "                    continue\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta    # 更新alpha j\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)    # 约束alpha j 到上下界\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): \n",
    "                    print \"j not moving enough\"\n",
    "                    continue    # alpha j 更新太少，继续iterate\n",
    "                #update i by the same amount as j\n",
    "                #the update is in the oppostie direction\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print \"iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "        if (alphaPairsChanged == 0): iter += 1\n",
    "        else: iter = 0\n",
    "        print \"iteration number: %d\" % iter\n",
    "    return b, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 i:0, pairs changed 1\n",
      "iter: 0 i:3, pairs changed 2\n",
      "L==H\n",
      "iter: 0 i:5, pairs changed 3\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "iter: 0 i:18, pairs changed 4\n",
      "L==H\n",
      "L==H\n",
      "j not moving enough\n",
      "L==H\n",
      "iter: 0 i:44, pairs changed 5\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:54, pairs changed 6\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "j not moving enough\n",
      "iteration number: 0\n",
      "iter: 0 i:0, pairs changed 1\n",
      "iter: 0 i:3, pairs changed 2\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "iter: 0 i:29, pairs changed 3\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "L==H\n",
      "j not moving enough\n",
      "iter: 0 i:70, pairs changed 4\n",
      "j not moving enough\n",
      "iter: 0 i:77, pairs changed 5\n",
      "iter: 0 i:82, pairs changed 6\n",
      "j not moving enough\n",
      "iteration number: 0\n",
      "j not moving enough\n",
      "iter: 0 i:5, pairs changed 1\n",
      "L==H\n",
      "L==H\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "L==H\n",
      "j not moving enough\n",
      "iter: 0 i:54, pairs changed 2\n",
      "j not moving enough\n",
      "iter: 0 i:69, pairs changed 3\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "iter: 0 i:82, pairs changed 4\n",
      "j not moving enough\n",
      "iteration number: 0\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "L==H\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "j not moving enough\n",
      "iteration number: 1\n"
     ]
    }
   ],
   "source": [
    "b, alphas = smoSimple(dataArr, labelArr, 0.6, 0.001, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not 0 elements in alpha matrix: [[ 0.08852666  0.01940376  0.02603069  0.00578016  0.16796809  0.02218113\n",
      "   0.00410569  0.05652747  0.00578016  0.0264563   0.02201125]]\n",
      "number of suport vector: (1, 11)\n",
      "suport vector 1: ; x_value: [3.542485, 1.977398]; label: -1.000000\n",
      "suport vector 2: ; x_value: [3.223038, -0.552392]; label: -1.000000\n",
      "suport vector 3: ; x_value: [3.457096, -0.082216]; label: -1.000000\n",
      "suport vector 4: ; x_value: [2.893743, -1.643468]; label: -1.000000\n",
      "suport vector 5: ; x_value: [5.286862, -2.358286]; label: 1.000000\n",
      "suport vector 6: ; x_value: [6.543888, 0.433164]; label: 1.000000\n",
      "suport vector 7: ; x_value: [-0.236713, -5.766721]; label: -1.000000\n",
      "suport vector 8: ; x_value: [1.966279, -1.840439]; label: -1.000000\n",
      "suport vector 9: ; x_value: [8.398012, 1.584918]; label: 1.000000\n",
      "suport vector 10: ; x_value: [8.54562, 2.788799]; label: 1.000000\n",
      "suport vector 11: ; x_value: [2.912122, -0.202359]; label: -1.000000\n"
     ]
    }
   ],
   "source": [
    "# 观察alpha矩阵中非零元素\n",
    "print \"not 0 elements in alpha matrix:\", alphas[alphas>0]\n",
    "# 了解支撑向量的数量\n",
    "print \"number of suport vector:\", shape(alphas[alphas>0])\n",
    "# 输出哪些数据点是支撑向量\n",
    "count = 0\n",
    "for i in range(100):\n",
    "    if alphas[i] > 0.0:\n",
    "        count += 1\n",
    "        print \"suport vector %d: ; x_value: %s; label: %f\" % (count, dataArr[i], labelArr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 利用完整Platt SMO算法加速优化\n",
    "Platt SMO算法通过一个外循环选择一个alpha值，并且其选择过程会在两种方式之间进行交替：\n",
    "- 在所有数据集上进行单遍扫描\n",
    "- 在非边界alpha（不等于边界0或C）中实现单边扫描 建立alpha值的列表，遍历该列表时，会跳过已知不会改变的alpha值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optStruct:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler):\n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m, 2)))    # m×2的缓存矩阵\n",
    "def calcEk(oS, k):\n",
    "    '''计算误差\n",
    "    传入：\n",
    "    oS：\n",
    "    k：\n",
    "    返回：\n",
    "    Ek 误差'''\n",
    "    fXk = float(multiply(oS.alphas, oS.labelMat).T*(oS.X*oS.X[k,:].T)) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "def selectJ(i, oS, Ei):\n",
    "    '''选择第二个alpha值，使用内循环启发方法\n",
    "    传入\n",
    "    i：\n",
    "    oS：\n",
    "    Ei：\n",
    "    返回\n",
    "    j：\n",
    "    Ej：\n",
    "    '''\n",
    "    maxK = -1\n",
    "    maxDeltaE = 0\n",
    "    Ej = 0\n",
    "    oS.eCache[i] = [1, Ei]\n",
    "    validEcacheList = nonzero(oS.eCache[:,0].A)[0]    # 构造一个非零表，返回的是非零E值对应的alpha值\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:\n",
    "            if k == i:\n",
    "                continue\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):    # 选择具有最大步长的j\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:    # 第一次循环，随机选择一个alpha j的值\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "def updateEk(oS, k):\n",
    "    '''计算误差并缓存'''\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1, Ek]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i,oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if (oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C) or (oS.labelMat[i]*Ei > oS.tol) and\\\n",
    "    (oS.alphas[i] > 0):\n",
    "        j, Ej = selectJ(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "        if oS.labelMat[i] != oS.labelMat[j]:\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[j])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H:\n",
    "            print \"L == H\"\n",
    "            return 0\n",
    "        eta = 2.0 * oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - \\\n",
    "              oS.X[j,:]*oS.X[j,:].T\n",
    "        if eta >= 0:\n",
    "            print \"eta>=0\"\n",
    "            return 0    \n",
    "        \n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta    # 更新alpha j\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)    # 约束alpha j 到上下界\n",
    "        updateEk(oS,j)    # 更新误差缓存，比简单SMO多了这一步\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): \n",
    "            print \"j not moving enough\"\n",
    "            return 0    # alpha j 更新太少，继续iterate\n",
    "        #update i by the same amount as j\n",
    "        #the update is in the oppostie direction\n",
    "        \n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*\\\n",
    "             oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*\\\n",
    "             oS.X[i,:]*oS.X[j,:].T\n",
    "        b2 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*\\\n",
    "             oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*\\\n",
    "             oS.X[j,:]*oS.X[j,:].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoP(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0)):\n",
    "    '''完整版Platt SMO算法，'''\n",
    "    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler)\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "    while iter < maxIter and (alphaPairsChanged > 0 or entireSet):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:\n",
    "            for i in range(oS.m):\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "            print \"fullSet, iter: %d i:%d, pairs changed %d\" %(iter, i, alphaPairsChanged)\n",
    "            iter += 1\n",
    "        else:\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print \"non-bound, iter: %d i:%d, pairs changed %d\" %(iter, i, alphaPairsChanged)\n",
    "            iter += 1\n",
    "        if entireSet :\n",
    "            entireSet = False\n",
    "        elif alphaPairsChanged == 0:\n",
    "              entireSet = True\n",
    "              print \"iteration number；%d\" % iter\n",
    "        return oS.b, oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "j not moving enough\n",
      "L == H\n",
      "j not moving enough\n",
      "L == H\n",
      "j not moving enough\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "fullSet, iter: 0 i:99, pairs changed 7\n"
     ]
    }
   ],
   "source": [
    "b, alphas = smoP(dataArr, labelArr, 0.6, 0.001, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWs(alphas, dataArr,classLabels):\n",
    "    X = mat(dataArr)\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(X)\n",
    "    w = zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i]*labelMat[i], X[i,:].T)\n",
    "    return w\n",
    "ws = calcWs(alphas,dataArr,labelArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict class: -1 ;ground truth class: -1\n",
      "predict class: -1 ;ground truth class: -1\n",
      "predict class: 1 ;ground truth class: 1\n",
      "predict class: -1 ;ground truth class: -1\n",
      "predict class: 0 ;ground truth class: 1\n",
      "predict class: 0 ;ground truth class: 1\n",
      "predict class: 1 ;ground truth class: 1\n",
      "predict class: -1 ;ground truth class: -1\n",
      "predict class: -1 ;ground truth class: -1\n",
      "predict class: -2 ;ground truth class: -1\n"
     ]
    }
   ],
   "source": [
    "# 检查分类的正确性\n",
    "dataMat = mat(dataArr)\n",
    "for i in range(10):\n",
    "    print \"predict class: %d ;ground truth class: %d\" % (dataMat[i] * mat(ws) +b, labelArr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 在复杂数据上应用核函数\n",
    "非线性可分的数据，需要使用核函数将数据转换到分类器理解的形式，本章主要介绍径向基函数。\n",
    "### 6.5.1 利用核函数将数据映射到高维空间\n",
    "对数据进行处理，把核函数当作装饰器或者接口，来处理特征空间的映射。SVM优化特别好的地方是，所有运算都能写成内积(inner product)，运用核技巧，将向量内积计算转换为核函数。接下来介绍一个流行的核函数。\n",
    "### 6.5.2 径向基核函数\n",
    "径向基函数将向量作为输入，输出是一个标量，其高斯形式是：\n",
    "$$k(x,y)=(\\frac{-||x-y||^2}{2\\sigma ^2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "def kernelTrans(X, A, kTup):\n",
    "    m, n = shape(X)\n",
    "    K = mat(zeros((m,1)))\n",
    "    if kTup[0] == 'lin':\n",
    "        K = X*A.T\n",
    "    elif kTup[0] == 'rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j, :] - A\n",
    "            K[j] = deltaRow * deltaRow.T\n",
    "        K = exp(K/(-1*kTup[1]**2))\n",
    "    else:\n",
    "        raise NameError('Houston We Have a Probem -- That Kernel is not recognized')\n",
    "    return K\n",
    "\n",
    "class optStruct_modify:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler, kTup):\n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m, 2)))\n",
    "        self.K = mat(zeros((self.m, self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL_modify(i,oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if (oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C) or (oS.labelMat[i]*Ei > oS.tol) and\\\n",
    "    (oS.alphas[i] > 0):\n",
    "        j, Ej = selectJ(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "        if oS.labelMat[i] != oS.labelMat[j]:\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[j])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H:\n",
    "            print \"L == H\"\n",
    "            return 0\n",
    "        eta = 2.0 * oS.K[i, j] - oS.K[i, i] - oS.K[j, j]\n",
    "        if eta >= 0:\n",
    "            print \"eta>=0\"\n",
    "            return 0    \n",
    "        \n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta    # 更新alpha j\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)    # 约束alpha j 到上下界\n",
    "        updateEk(oS,j)    # 更新误差缓存，比简单SMO多了这一步\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): \n",
    "            print \"j not moving enough\"\n",
    "            return 0    # alpha j 更新太少，继续iterate\n",
    "        #update i by the same amount as j\n",
    "        #the update is in the oppostie direction\n",
    "        \n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])\n",
    "        b1 = oS.b -Ei - oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i]-\\\n",
    "             oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n",
    "        b2 = oS.b -Ej - oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]-\\\n",
    "             oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEk_modify(oS, k):\n",
    "    fXk = float(multiply(oS.alphas, oS.labelMat).T*oS.K[:, k]+oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoP_modify(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0)):\n",
    "    '''完整版Platt SMO算法，'''\n",
    "    oS = optStruct_modify(mat(dataMatIn), mat(classLabels).transpose(), C, toler, kTup)\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "    while iter < maxIter and (alphaPairsChanged > 0 or entireSet):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:\n",
    "            for i in range(oS.m):\n",
    "                alphaPairsChanged += innerL_modify(i, oS)\n",
    "            print \"fullSet, iter: %d i:%d, pairs changed %d\" %(iter, i, alphaPairsChanged)\n",
    "            iter += 1\n",
    "        else:\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL_modify(i, oS)\n",
    "                print \"non-bound, iter: %d i:%d, pairs changed %d\" %(iter, i, alphaPairsChanged)\n",
    "            iter += 1\n",
    "        if entireSet :\n",
    "            entireSet = False\n",
    "        elif alphaPairsChanged == 0:\n",
    "              entireSet = True\n",
    "              print \"iteration number；%d\" % iter\n",
    "        return oS.b, oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRbf(k1=1.3):\n",
    "    dataArr, labelArr = loadDataSet('testSetRBF.txt')\n",
    "    b, alphas = smoP_modify(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', k1))\n",
    "    dataMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    svInd = nonzero(alphas.A>0)[0]\n",
    "    sVs = dataMat[svInd]\n",
    "    labelSV = labelMat[svInd]\n",
    "    print \"there are %d Support Vectors\" % shape(sVs)[0]\n",
    "    m, n = shape(dataMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, dataMat[i,:], ('rbf', k1))\n",
    "        predict = kernelEval.T*multiply(labelSV, alphas[svInd]) + b\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print \"the training error rate is: %f\" % (float(errorCount/m))\n",
    "    dataArr, labelArr = loadDataSet('testSetRBF2.txt')\n",
    "    errorCount = 0\n",
    "    dataMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    m, n = shape(dataMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, dataMat[i,:], ('rbf', k1))\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print \"the training error rate is: %f\" % (float(errorCount/m))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L == H\n",
      "fullSet, iter: 0 i:99, pairs changed 73\n",
      "there are 72 Support Vectors\n",
      "the training error rate is: 0.000000\n",
      "the training error rate is: 0.000000\n"
     ]
    }
   ],
   "source": [
    "testRbf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 示例：手写识别问题回顾\n",
    "1. 收集数据：提供文本文件\n",
    "2. 准备数据：基于二值图像构造向量\n",
    "3. 分析数据：对图像向量进行目测\n",
    "4. 训练算法：采用两种不同的核函数，并对RBF采用不同设置来运行SMO算法\n",
    "5. 测试算法：编写一个函数来测试不同的核函数并计算错误率\n",
    "6. 使用算法：不打算深入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = zeros((1, 1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0, 32*i+j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "def loadImages(dirName):\n",
    "    from os import listdir\n",
    "    hwLabels = []\n",
    "    trainingFileList = listdir(dirName)\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        if classNumStr == 9:\n",
    "            hwLabels.append(-1)\n",
    "        else:\n",
    "            hwLabels.append(1)\n",
    "        trainingMat[i,:] = img2vector('%s/%s' %(dirName, fileNameStr))\n",
    "    return trainingMat, hwLabels\n",
    "def testDigits(kTup=('rbf', 10)):\n",
    "    dataArr, labelArr = loadImages('trainingDigits')\n",
    "    b, alphas = smoP_modify(dataArr, labelArr, 200, 0.0001, 10000, kTup)\n",
    "    dataMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    svInd = nonzero(alphas.A > 0)[0]\n",
    "    sVs = dataMat[svInd]\n",
    "    labelSV = labelMat[svInd]\n",
    "    print \"there are %d Support Vectors\" % shape(sVs)[0]\n",
    "    m, n = shape(dataMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, dataMat[i,:], kTup)\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print \"the training error rate is: %f\" % (float(errorCount)/m)\n",
    "    dataArr, labelArr = loadImages('testDigits')\n",
    "    errorCount = 0\n",
    "    dataMat, labelMat = mat(dataArr), mat(labelArr).transpose()\n",
    "    m, n = shape(dataMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, dataMat[i,:], kTup)\n",
    "        predict = kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict) != sign(labelArr[i]):\n",
    "            errorCount += 1\n",
    "    print \"the test error rate is: %f\" % (float(errorCount)/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "L == H\n",
      "fullSet, iter: 0 i:401, pairs changed 43\n",
      "there are 2 Support Vectors\n",
      "the training error rate is: 0.492537\n",
      "the test error rate is: 0.521505\n"
     ]
    }
   ],
   "source": [
    "testDigits(('rbf', 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 本章小结\n",
    "支持向量机是一种分类器，之所以成为“机”是因为会产生一个二值决策结果，它是一种决策“机”。支持向量机的泛化错误比较低，学习到的结果具有很好的推广性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2.7]",
   "language": "python",
   "name": "conda-env-py2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
