{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#7.1-基于数据集多重抽样的分类器\" data-toc-modified-id=\"7.1-基于数据集多重抽样的分类器-1\">7.1 基于数据集多重抽样的分类器</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1.1-bagging：基于数据随机重抽样的分类器构建方法\" data-toc-modified-id=\"7.1.1-bagging：基于数据随机重抽样的分类器构建方法-1.1\">7.1.1 bagging：基于数据随机重抽样的分类器构建方法</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1.2-boosting\" data-toc-modified-id=\"7.1.2-boosting-1.1.1\">7.1.2 boosting</a></span></li></ul></li></ul></li><li><span><a href=\"#7.2-训练算法：基于错误提升分类器的性能\" data-toc-modified-id=\"7.2-训练算法：基于错误提升分类器的性能-2\">7.2 训练算法：基于错误提升分类器的性能</a></span></li><li><span><a href=\"#基于单层决策树构建的弱分类器\" data-toc-modified-id=\"基于单层决策树构建的弱分类器-3\">基于单层决策树构建的弱分类器</a></span></li><li><span><a href=\"#7.4-完整AdaBoost算法实现\" data-toc-modified-id=\"7.4-完整AdaBoost算法实现-4\">7.4 完整AdaBoost算法实现</a></span></li><li><span><a href=\"#7.5-测试算法：基于AdaBoost的分类\" data-toc-modified-id=\"7.5-测试算法：基于AdaBoost的分类-5\">7.5 测试算法：基于AdaBoost的分类</a></span></li><li><span><a href=\"#7.6-示例：在一个难数据集应用AdaBoost\" data-toc-modified-id=\"7.6-示例：在一个难数据集应用AdaBoost-6\">7.6 示例：在一个难数据集应用AdaBoost</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用AdaBoost元算法提高分类性能\n",
    "元算法是对其他算法进行组合的一种方式。某些人认为AdaBoost是最好的机器学习监督算法，该方法是机器学习工具箱中强有力的工具之一。\n",
    "## 7.1 基于数据集多重抽样的分类器\n",
    "集成的方法有很多方式：可以是不同算法的集成，也可以是一个算法不同设置的集成，还可以是一个数据集不同部分分配给不同分类器的集成。\n",
    "**AdaBoost**\n",
    "1. 优点：泛化错误率低，易编码，可以用在大部分分类器上，无参数调节\n",
    "2. 缺点：对离群点敏感\n",
    "3. 适用数据类型：数值型和标称型\n",
    "### 7.1.1 bagging：基于数据随机重抽样的分类器构建方法\n",
    "自举汇聚法（bootstrap aggregating）也称为bagging方法，在原始数据集上重抽样S次构建出大小和原数据集一样的的S个数据集，这S个数据集可以有重复的样本，也有相对于原始数据集缺失些样本以保证大小一致。更先进的bagging方法是随机森林。\n",
    "#### 7.1.2 boosting\n",
    "boosting和bagging比较相似，不同在于boosting是串行的，用来关注那些被前边分类器错误分类的数据集，从而生成新的分类器。Boosting有多种方法，本章只关注AdaBoost。\n",
    "**AdaBoost一般流程**\n",
    "1. 收集数据：可以使用任何方法\n",
    "2. 准备数据：依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器。\n",
    "3. 分析数据：任意方法\n",
    "4. 训练算法：AdaBoost的大部分时间都用在了训练上面，分类器将多次在同一个数据集上训练弱分类器\n",
    "5. 测试算法：计算分类的错误率\n",
    "6. 使用算法：同SVM一样，AdaBoost预测两个类别中的一个，如果想应用到多个类别中，就需要象SVM那样修改。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 训练算法：基于错误提升分类器的性能\n",
    "Adaboost 是adaptive boosting的缩写，其运行过程如下：训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量D。为了从所有弱分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个弱分类器错误率进行计算的，其中，错误率$\\xi$定义为：\n",
    "$$\\xi = \\frac{未分类正确的样本数目}{所有样本数目}$$\n",
    "而$\\alpha$的计算公式如下：\n",
    "$$\\alpha = \\frac{1}{2}ln\\left({\\frac{1-\\xi}{\\xi}}\\right)$$\n",
    "D的计算方式如下：\n",
    "如果某个样本被正确分类：\n",
    "$$D_i^{(t+1)} = \\frac{D_i^{(t)}e^{-a}}{Sum(D)}$$\n",
    "如果某个样本被错误分类：\n",
    "$$D_i^{(t+1)} = \\frac{D_i^{(t)}e^{a}}{Sum(D)}$$\n",
    "\n",
    "AdaBoost算法会不断地重复训练和调整权重的过程，知道训练错误率为0或者弱分类器的数目达到用户指定为止。\n",
    "## 基于单层决策树构建的弱分类器\n",
    "单层决策树是一种简单的决策树，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "def loadSimpData():\n",
    "    datMat = matrix([[1.0, 2.1],\n",
    "                     [2.0, 1.1],\n",
    "                     [1.3, 1.0],\n",
    "                     [1.0, 1.0],\n",
    "                     [2.0, 1.0]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat, classLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造多个函数来建立单层决策树，第一个函数将用于测试是否有某个值小于或者大于我们正在测试的阈值;第二个函数会在一个加权数据集中循环，并找到具有最低错误率的单层决策树。\n",
    "伪代码如下：\n",
    "\n",
    "    初始化最小错误率minError为正无穷\n",
    "    对数据集中每一个特征（第一层循环）：\n",
    "        对每个步长（第二层循环）：\n",
    "            对每个不等号（第三层循环）：\n",
    "            建立一棵单层决策树并利用加权数据集对它进行测试\n",
    "            如果错误率低于minError，则将当前单层决策树设为最佳单层决策树\n",
    "    返回最佳单层决策树\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "#     print dataMatrix, dimen, threshVal, threshIneq\n",
    "    retArray = ones((shape(dataMatrix)[0],1))\n",
    "    if threshIneq == 'It':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "def buildStump(dataArr, classLabels, D):\n",
    "    dataMatrix = mat(dataArr)\n",
    "    labelMat = mat(classLabels).T\n",
    "    m, n = shape(dataMatrix)\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}\n",
    "    bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:,i].min()\n",
    "        rangeMax = dataMatrix[:,i].max()\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1, int(numSteps)+1):\n",
    "            for inequal in ['It', 'gt']:\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                errArr = mat(ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr\n",
    "#                 print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" \\\n",
    "#                       % (i, threshVal, inequal, weightedError)\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = mat(ones((5,1))/5)\n",
    "datMat, classLabels = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'It', 'thresh': 1.3}, matrix([[ 0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildStump(datMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 完整AdaBoost算法实现\n",
    "伪代码如下：\n",
    "    \n",
    "    对每次迭代：\n",
    "      利用buildStump()函数找到最佳的单层决策树\n",
    "      将最佳的单层决策树加入到单层决策树数组\n",
    "      计算alpha\n",
    "      计算新的权重向量\n",
    "      更新累计类别估计量\n",
    "      如果错误率等于0.0,则退出循环\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)\n",
    "    aggClassEst = mat(zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D)\n",
    "#         print \"D:\", D.T\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "#         print \"classEst:\", classEst.T\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T, classEst)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        aggClassEst += alpha*classEst\n",
    "#         print \"aggClassEst: \", aggClassEst.T\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m, 1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print \"total error: \", errorRate, \"\\n\"\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEst: [[-1.  1. -1. -1.  1.]]\n",
      "total error:  0.2 \n",
      "\n",
      "classEst: [[ 1.  1. -1. -1. -1.]]\n",
      "total error:  0.2 \n",
      "\n",
      "classEst: [[ 1.  1.  1.  1.  1.]]\n",
      "total error:  0.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'It', 'thresh': 1.3},\n",
       " {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'It', 'thresh': 1.0},\n",
       " {'alpha': 0.8958797346140273,\n",
       "  'dim': 0,\n",
       "  'ineq': 'It',\n",
       "  'thresh': 0.90000000000000002}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaBoostTrainDS(datMat, classLabels, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 测试算法：基于AdaBoost的分类\n",
    "一旦拥有多个弱分类器和其对应的alpha值，测试就相当容易了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = mat(datToClass)\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],\\\n",
    "                                classifierArr[i]['thresh'], classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "#         print aggClassEst\n",
    "    return sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEst: [[-1.  1. -1. -1.  1.]]\n",
      "total error:  0.2 \n",
      "\n",
      "classEst: [[ 1.  1. -1. -1. -1.]]\n",
      "total error:  0.2 \n",
      "\n",
      "classEst: [[ 1.  1.  1.  1.  1.]]\n",
      "total error:  0.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datArr, labelArr = loadSimpData()\n",
    "classifierArr = adaBoostTrainDS(datArr, labelArr, 30)\n",
    "adaClassify([0,0],classifierArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 示例：在一个难数据集应用AdaBoost\n",
    "利用第4章使用的氙气病数据集，查看利用多个单层决策树和AdaBoost能不能预测的更准确。\n",
    "\n",
    "1. 收集数据：提供文本文件\n",
    "2. 准备数据：确保类别标签+1和-1而非1和0\n",
    "3. 分析数据：手工检查数据\n",
    "4. 训练算法：在数据集上，利用adaBoostTrainDS()函数训练出一系列分类器\n",
    "5. 测试算法：我们拥有两个数据集，在采用随机抽样的方法下，我们就会对AdaBoost和Logistic回归的结果进行完全对等的比较\n",
    "6. 使用算法：观察该例子上的错误率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat, labelMat = [], []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classEst: [[-1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.\n",
      "   1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "   1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.\n",
      "  -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.]]\n",
      "total error:  0.284280936455 \n",
      "\n",
      "classEst: [[ 1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "   1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.\n",
      "   1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      "   1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.]]\n",
      "total error:  0.284280936455 \n",
      "\n",
      "classEst: [[-1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1.\n",
      "  -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.\n",
      "  -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.\n",
      "   1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  -1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.\n",
      "  -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.\n",
      "   1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.\n",
      "   1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1.]]\n",
      "total error:  0.247491638796 \n",
      "\n",
      "classEst: [[-1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.\n",
      "   1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "  -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.]]\n",
      "total error:  0.247491638796 \n",
      "\n",
      "classEst: [[ 1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.\n",
      "  -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.]]\n",
      "total error:  0.254180602007 \n",
      "\n",
      "classEst: [[-1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.\n",
      "   1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      "   1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1.\n",
      "   1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.\n",
      "  -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  -1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1.\n",
      "   1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1.\n",
      "  -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      "   1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.\n",
      "   1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n",
      "  -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
      "  -1. -1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.]]\n",
      "total error:  0.240802675585 \n",
      "\n",
      "classEst: [[-1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      "  -1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.\n",
      "  -1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.\n",
      "  -1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      "  -1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1.\n",
      "  -1.  1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.  1.  1.\n",
      "   1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
      "  -1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      "  -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.\n",
      "  -1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.\n",
      "   1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.\n",
      "   1.  1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.\n",
      "  -1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1.]]\n",
      "total error:  0.240802675585 \n",
      "\n",
      "classEst: [[ 1. -1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  -1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.\n",
      "   1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.\n",
      "   1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1.\n",
      "   1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.\n",
      "  -1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  -1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.\n",
      "   1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.\n",
      "  -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.\n",
      "   1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  -1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1.\n",
      "  -1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.]]\n",
      "total error:  0.220735785953 \n",
      "\n",
      "classEst: [[ 1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
      "   1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.\n",
      "  -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.]]\n",
      "total error:  0.247491638796 \n",
      "\n",
      "classEst: [[-1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.\n",
      "  -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
      "  -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1.\n",
      "   1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.\n",
      "  -1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.\n",
      "   1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
      "  -1.  1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      "  -1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1.\n",
      "  -1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.\n",
      "   1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "  -1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
      "  -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.\n",
      "  -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1.\n",
      "  -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.\n",
      "   1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1.]]\n",
      "total error:  0.230769230769 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "datArr, labelArr = loadDataSet('horseColicTraining2.txt')\n",
    "classifierArray = adaBoostTrainDS(datArr, labelArr, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2.7]",
   "language": "python",
   "name": "conda-env-py2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
